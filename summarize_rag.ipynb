{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a0131f",
   "metadata": {},
   "source": [
    "# Summarization by RAG \n",
    "\n",
    "This notebook walks through how to use RAG for summarization over a list of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5660bf",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "First we prepare the data. For this example we create multiple documents from one long one, but these documents could be fetched in any manner (the point of this notebook to highlight what to do AFTER you fetch the documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1340a648-4f30-47e7-a937-b9e9e06486b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('azure.env',override = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d5c99",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57b8dd9-2874-4e71-813e-fc70c36c0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings,AzureChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from langchain.schema import Document\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain.schema.runnable import RunnableMap\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import PostgresChatMessageHistory\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "\n",
    "from azure.ai.documentintelligence.models import DocumentAnalysisFeature\n",
    "from langchain_community.document_loaders.doc_intelligence import AzureAIDocumentIntelligenceLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953044b-9360-4334-a5ee-b49ac2f3b3b0",
   "metadata": {},
   "source": [
    "### Uploading the document through Azure Document Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "api_endpoint = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "print(f\"API Key: {api_key}, Type: {type(api_key)}\")\n",
    "print(f\"API Endpoint: {api_endpoint}, Type: {type(api_endpoint)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4d9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = AzureAIDocumentIntelligenceLoader(file_path=r'C:\\Users\\nag\\Documents\\Microsoft\\Customer data\\Infosys_Legal_docs_summary\\Health System Provider Agreement.pdf', \n",
    "                                           api_key = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\"), \n",
    "                                           api_endpoint = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\"),\n",
    "                                           api_model=\"prebuilt-layout\",\n",
    "                                           api_version=\"2024-02-29-preview\",\n",
    "                                           mode='markdown',\n",
    "                                           analysis_features = [DocumentAnalysisFeature.OCR_HIGH_RESOLUTION])\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d23f9-3f68-4546-83ac-9ae6a53911bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown(docs[-1].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e3b64-3113-480a-9cf2-49407fd5b700",
   "metadata": {},
   "source": [
    "### Split the document into chunks base on markdown headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596f74bb-8f79-4c89-bde9-fd11609ad3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom headers and patterns for splitting legal documents\n",
    "# headers_to_split_on = [\n",
    "#     r\"^\\d+\\.\\s\",  # Matches \"1.\", \"2.\", etc.\n",
    "#     r\"^\\d+\\.\\d+\",  # Matches \"2.1\", \"2.2\", etc.\n",
    "#     r\"^[A-Z ]{2,50}$\"  # Matches uppercase headers\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f885b3b0-13bc-4451-882a-2d534fd8e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23431038-bdd7-4ccb-b131-f1b8b9a02dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "docs_string = docs[0].page_content\n",
    "docs_result = text_splitter.split_text(docs_string)\n",
    "\n",
    "print(\"Length of splits: \" + str(len(docs_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdacf1-dce0-4890-90ab-fd120675d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "from langchain_text_splitters.base import Language, TextSplitter\n",
    "\n",
    "class CustomCharacterTextSplitter(TextSplitter):\n",
    "    \"\"\"Splitting text that looks at characters.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, separator: str = \"\\n\\n\", is_separator_regex: bool = False, **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"Create a new TextSplitter.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self._separator = separator\n",
    "        self._is_separator_regex = is_separator_regex\n",
    "\n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Split incoming text and return chunks.\"\"\"\n",
    "        # First we naively split the large input into a bunch of smaller ones.\n",
    "        separator = (\n",
    "            self._separator if self._is_separator_regex else re.escape(self._separator)\n",
    "        )\n",
    "        splits = re.split(separator, text, flags=re.DOTALL) \n",
    "        splits = [part for part in splits if part.strip()]\n",
    "        return splits\n",
    "\n",
    "text_splitter = CustomCharacterTextSplitter(separator=r'(<figure>.*?</figure>)', is_separator_regex=True)\n",
    "child_docs  = text_splitter.split_documents(docs_result)\n",
    "print(\"Length of splits: \" + str(len(child_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3169d09-bd4f-4fd0-8bc6-066586f6f6cf",
   "metadata": {},
   "source": [
    "### Load the LangChain OpenAI Embedding Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7dff5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_deployment=\"text-embedding-ada-002\",\n",
    "    openai_api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint =os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c8993",
   "metadata": {},
   "source": [
    "### Create the Azure AI Search Index Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b65d5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings, OpenAIEmbeddings\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights\n",
    ")\n",
    "embedding_function = aoai_embeddings.embed_query\n",
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=False,\n",
    "    ),\n",
    "    # Additional field to store the title\n",
    "    SearchableField(\n",
    "        name=\"header\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field for filtering on document source\n",
    "    SimpleField(\n",
    "        name=\"image\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=False,\n",
    "        searchable=False,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61350f9",
   "metadata": {},
   "source": [
    "### Create the AI Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bcbe31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name: str = \"langchain-vector-demo-custom3\"\n",
    "\n",
    "vector_store_multi_modal: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=os.environ[\"AZURE_SEARCH_ENDPOINT\"],\n",
    "    azure_search_key=os.environ[\"AZURE_SEARCH_KEY\"],\n",
    "    index_name=index_name,\n",
    "    embedding_function=embedding_function,\n",
    "    fields=fields,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b56ed3d9-4384-47d7-bf89-b0b15f00ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "def find_figure_indices(text):\n",
    "    pattern = r'!\\[\\]\\(figures/(\\d+)\\)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    indices = [int(match) for match in matches]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9567e",
   "metadata": {},
   "source": [
    "### Ingest the chunks into Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_metadata = docs[-1].metadata['images']\n",
    "lst_docs = []\n",
    "for doc in child_docs:\n",
    "    figure_indices = find_figure_indices(doc.page_content)\n",
    "    if figure_indices:\n",
    "        for figure_indice in figure_indices:\n",
    "            image = image_metadata[figure_indice]\n",
    "            doc_result = Document(page_content = doc.page_content, metadata={\"header\": json.dumps(doc.metadata), \"source\": \"multi_page_table.pdf\", \"image\": image})\n",
    "            lst_docs.append(doc_result)\n",
    "    else:\n",
    "        doc_result = Document(page_content = doc.page_content, metadata={\"header\": json.dumps(doc.metadata), \"source\": \"multi_page_table.pdf\", \"image\": None})\n",
    "        lst_docs.append(doc_result)\n",
    "vector_store_multi_modal.add_documents(documents=lst_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8526daa2-bc83-4788-bfd2-1874a918d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = await FAISS.afrom_documents(documents=child_docs, embedding=aoai_embeddings)\n",
    "retriever_base = index.as_retriever(search_type=\"similarity\",search_kwargs = {\"k\" : 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822be0d2",
   "metadata": {},
   "source": [
    "### Lets do the RAG Now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05658491-9ce9-4dd0-8dc6-fa73d3b7cc95",
   "metadata": {},
   "source": [
    "### Load the AOAI Chat Class from LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe37bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(api_key = os.environ[\"AZURE_OPENAI_API_KEY\"],  \n",
    "                      api_version = \"2024-06-01\",\n",
    "                      azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "                      model= os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "                      streaming=True)\n",
    "llm([HumanMessage(\"Hi\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92890db2-0cab-48e6-8025-7f9e825579d5",
   "metadata": {},
   "source": [
    "### Summary By RAG with Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922fd09-b85b-41a4-b2ac-47f8bb68675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "from langchain.schema.runnable import RunnableMap\n",
    "\n",
    "def format_docs(docs):\n",
    "    to_return =  \"\\n\\n\".join(str(doc.metadata) + \"\\n\" + doc.page_content for doc in docs)\n",
    "    return to_return\n",
    "    \n",
    "rag_chain_from_docs = (\n",
    "    {\n",
    "        \"context\": lambda input: format_docs(input[\"documents\"]),\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain_with_source = RunnableMap(\n",
    "    {\"documents\": retriever_base, \"question\": RunnablePassthrough()}\n",
    ") | {\n",
    "    \"documents\": lambda input: [doc.metadata for doc in input[\"documents\"]],\n",
    "    \"answer\": rag_chain_from_docs,\n",
    "}\n",
    "# rag_chain_with_source.invoke(\"Does Quality consultant has Controlling field office write permission?\")\n",
    "rag_result = rag_chain_with_source.invoke(\"Generate a summary of the document highlighting the main legal conditions also important points to be noted in markdown format\")\n",
    "\n",
    "r_result = rag_result[\"answer\"]\n",
    "print(r_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852c554-2b19-4df5-8f44-d1318519b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(r_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725180f-a569-4c21-883e-160ffc74d8cc",
   "metadata": {},
   "source": [
    "## Complete Doc Ingestion Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec94ec-40a3-4512-bd2d-d6eba47f5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Step 4: Create the prompt\n",
    "prompt_template = \"\"\"\n",
    "You are a summarization assistant. Summarize the following document:\n",
    "\n",
    "{docs_string}\n",
    "\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"docs_string\"],\n",
    "    template=prompt_template\n",
    ")\n",
    "\n",
    "# Step 5: Run the summarization\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "result = chain.run({\"docs_string\": docs_string})\n",
    "\n",
    "# Print the result\n",
    "print(\"Summary:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4708d535-5503-435b-b04a-6c8bb2d87624",
   "metadata": {},
   "source": [
    "# Summary in Markdown with Context Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afaccb-68e4-4401-b834-39c88f019bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6d8a5-d534-47c3-b47c-f50cb3148559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1677b440931f40d89ef8be7bf03acb108ce003de0ac9b18e8d43753ea2e7103"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
